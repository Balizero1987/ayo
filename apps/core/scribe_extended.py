#!/usr/bin/env python3
"""
THE SCRIBE EXTENDED: Additional Documentation Generators
Generates: MIGRATIONS_CHANGELOG.md, PLUGIN_REGISTRY.md, INFRASTRUCTURE_STATUS.md
"""

import ast
import re
import yaml
import toml
from pathlib import Path
from typing import Dict, Optional
from datetime import datetime
from collections import defaultdict


class Colors:
    """Terminal colors"""

    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKCYAN = "\033[96m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"


class MigrationsGenerator:
    """Generate MIGRATIONS_CHANGELOG.md from migration files"""

    def __init__(self, backend_dir: Path, docs_dir: Path):
        self.migrations_dir = backend_dir / "migrations"
        self.db_migrations_dir = backend_dir / "db" / "migrations"
        self.output_file = docs_dir / "MIGRATIONS_CHANGELOG.md"

    def extract_migration_info(self, file_path: Path) -> Optional[Dict]:
        """Extract migration number, docstring, and SQL from a migration file"""
        try:
            content = file_path.read_text(encoding="utf-8")

            # Extract migration number from filename
            match = re.search(r"migration[_-]?(\d+)", file_path.stem, re.IGNORECASE)
            if not match:
                match = re.search(r"^(\d+)", file_path.stem)

            migration_num = match.group(1) if match else "?"

            # For Python files, parse AST for docstring
            if file_path.suffix == ".py":
                try:
                    tree = ast.parse(content)
                    docstring = ast.get_docstring(tree) or ""
                except SyntaxError:
                    docstring = ""

                # Extract date from docstring if present
                date_match = re.search(r"Date:\s*(\d{4}-\d{2}-\d{2})", docstring)
                date = date_match.group(1) if date_match else "Unknown"

                # Extract purpose
                purpose_match = re.search(r"Purpose:\s*(.+?)(?:\n|$)", docstring)
                purpose = (
                    purpose_match.group(1).strip()
                    if purpose_match
                    else docstring.split("\n")[0]
                    if docstring
                    else file_path.stem
                )

                return {
                    "number": migration_num,
                    "name": file_path.stem,
                    "type": "Python",
                    "date": date,
                    "purpose": purpose,
                    "docstring": docstring,
                }

            # For SQL files
            elif file_path.suffix == ".sql":
                # Extract comment header
                lines = content.split("\n")
                comments = []
                for line in lines:
                    if line.strip().startswith("--"):
                        comments.append(line.strip("- ").strip())
                    elif line.strip() and not line.strip().startswith("--"):
                        break

                purpose = comments[0] if comments else file_path.stem

                return {
                    "number": migration_num,
                    "name": file_path.stem,
                    "type": "SQL",
                    "date": "Unknown",
                    "purpose": purpose,
                    "docstring": "\n".join(comments),
                }

            return None
        except Exception as e:
            print(f"{Colors.WARNING}âš  Error reading {file_path}: {e}{Colors.ENDC}")
            return None

    def generate(self) -> bool:
        """Generate MIGRATIONS_CHANGELOG.md"""
        migrations = []

        # Scan Python migrations
        if self.migrations_dir.exists():
            for f in sorted(self.migrations_dir.glob("migration_*.py")):
                info = self.extract_migration_info(f)
                if info:
                    migrations.append(info)

        # Scan SQL migrations
        if self.db_migrations_dir.exists():
            for f in sorted(self.db_migrations_dir.glob("*.sql")):
                info = self.extract_migration_info(f)
                if info:
                    migrations.append(info)

        # Sort by migration number
        migrations.sort(
            key=lambda x: int(x["number"]) if x["number"].isdigit() else 999
        )

        # Generate markdown
        lines = [
            "# MIGRATIONS CHANGELOG",
            "",
            f"*Auto-generated by The Scribe on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            "> **Note:** This document is automatically updated. Do not edit manually.",
            "",
            "---",
            "",
            "## Summary",
            "",
            f"- **Total Migrations:** {len(migrations)}",
            f"- **Python Migrations:** {len([m for m in migrations if m['type'] == 'Python'])}",
            f"- **SQL Migrations:** {len([m for m in migrations if m['type'] == 'SQL'])}",
            "",
            "---",
            "",
            "## Migration History",
            "",
            "| # | Name | Type | Date | Purpose |",
            "|---|------|------|------|---------|",
        ]

        for m in migrations:
            purpose_short = (
                m["purpose"][:60] + "..." if len(m["purpose"]) > 60 else m["purpose"]
            )
            lines.append(
                f"| {m['number']} | `{m['name']}` | {m['type']} | {m['date']} | {purpose_short} |"
            )

        lines.extend(
            [
                "",
                "---",
                "",
                "## Detailed Descriptions",
                "",
            ]
        )

        for m in migrations:
            lines.extend(
                [
                    f"### Migration {m['number']}: {m['name']}",
                    "",
                    f"- **Type:** {m['type']}",
                    f"- **Date:** {m['date']}",
                    "",
                    "**Description:**",
                    "",
                    m["docstring"] if m["docstring"] else "_No description available_",
                    "",
                    "---",
                    "",
                ]
            )

        lines.append(f"*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        self.output_file.write_text("\n".join(lines), encoding="utf-8")
        print(f"{Colors.OKGREEN}âœ” Generated {self.output_file}{Colors.ENDC}")
        return True


class PluginRegistryGenerator:
    """Generate PLUGIN_REGISTRY.md from plugin files"""

    def __init__(self, backend_dir: Path, docs_dir: Path):
        self.plugins_dir = backend_dir / "plugins"
        self.core_plugins_dir = backend_dir / "core" / "plugins"
        self.output_file = docs_dir / "PLUGIN_REGISTRY.md"

    def extract_plugin_info(self, file_path: Path) -> Optional[Dict]:
        """Extract plugin class info from a plugin file"""
        try:
            content = file_path.read_text(encoding="utf-8")
            tree = ast.parse(content)

            module_docstring = ast.get_docstring(tree) or ""

            # Find plugin classes (inherit from Plugin or have 'Plugin' in name)
            plugins = []
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    is_plugin = "plugin" in node.name.lower()
                    for base in node.bases:
                        if isinstance(base, ast.Name) and "Plugin" in base.id:
                            is_plugin = True

                    if is_plugin:
                        class_docstring = ast.get_docstring(node) or ""

                        # Find execute method
                        execute_doc = ""
                        for item in node.body:
                            if isinstance(
                                item, (ast.FunctionDef, ast.AsyncFunctionDef)
                            ):
                                if item.name == "execute":
                                    execute_doc = ast.get_docstring(item) or ""

                        plugins.append(
                            {
                                "class_name": node.name,
                                "docstring": class_docstring,
                                "execute_doc": execute_doc,
                            }
                        )

            if plugins:
                return {
                    "file": file_path.stem,
                    "path": str(file_path),
                    "module_docstring": module_docstring,
                    "plugins": plugins,
                }
            return None
        except Exception as e:
            print(f"{Colors.WARNING}âš  Error parsing {file_path}: {e}{Colors.ENDC}")
            return None

    def generate(self) -> bool:
        """Generate PLUGIN_REGISTRY.md"""
        plugin_files = []

        # Scan plugins directory
        if self.plugins_dir.exists():
            for f in self.plugins_dir.rglob("*_plugin.py"):
                info = self.extract_plugin_info(f)
                if info:
                    plugin_files.append(info)

        # Count total plugins
        total_plugins = sum(len(pf["plugins"]) for pf in plugin_files)

        # Group by category (subdirectory)
        categories = defaultdict(list)
        for pf in plugin_files:
            path = Path(pf["path"])
            if self.plugins_dir in path.parents:
                rel = path.relative_to(self.plugins_dir)
                category = rel.parts[0] if len(rel.parts) > 1 else "root"
            else:
                category = "core"
            categories[category].append(pf)

        # Generate markdown
        lines = [
            "# PLUGIN REGISTRY",
            "",
            f"*Auto-generated by The Scribe on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            "> **Note:** This document is automatically updated. Do not edit manually.",
            "",
            "---",
            "",
            "## Summary",
            "",
            f"- **Total Plugin Files:** {len(plugin_files)}",
            f"- **Total Plugin Classes:** {total_plugins}",
            f"- **Categories:** {', '.join(sorted(categories.keys()))}",
            "",
            "---",
            "",
            "## Plugin Categories",
            "",
        ]

        for category in sorted(categories.keys()):
            cat_plugins = categories[category]
            lines.extend(
                [
                    f"### {category.replace('_', ' ').title()}",
                    "",
                    "| Plugin | Class | Description |",
                    "|--------|-------|-------------|",
                ]
            )

            for pf in cat_plugins:
                for plugin in pf["plugins"]:
                    desc = (
                        plugin["docstring"].split("\n")[0][:50]
                        if plugin["docstring"]
                        else "_No description_"
                    )
                    lines.append(
                        f"| `{pf['file']}` | `{plugin['class_name']}` | {desc} |"
                    )

            lines.append("")

        lines.extend(
            [
                "---",
                "",
                "## Detailed Plugin Documentation",
                "",
            ]
        )

        for pf in plugin_files:
            lines.extend(
                [
                    f"### {pf['file']}.py",
                    "",
                    f"**Path:** `{pf['path']}`",
                    "",
                ]
            )

            if pf["module_docstring"]:
                lines.extend([pf["module_docstring"], ""])

            for plugin in pf["plugins"]:
                lines.extend(
                    [
                        f"#### Class: `{plugin['class_name']}`",
                        "",
                    ]
                )
                if plugin["docstring"]:
                    lines.extend([plugin["docstring"], ""])
                if plugin["execute_doc"]:
                    lines.extend(["**Execute Method:**", "", plugin["execute_doc"], ""])

            lines.extend(["---", ""])

        lines.append(f"*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        self.output_file.write_text("\n".join(lines), encoding="utf-8")
        print(f"{Colors.OKGREEN}âœ” Generated {self.output_file}{Colors.ENDC}")
        return True


class InfrastructureGenerator:
    """Generate INFRASTRUCTURE_STATUS.md from config files"""

    def __init__(self, root_dir: Path, docs_dir: Path):
        self.root_dir = root_dir
        self.config_dir = root_dir / "config"
        self.output_file = docs_dir / "INFRASTRUCTURE_STATUS.md"

    def parse_fly_toml(self, file_path: Path) -> Optional[Dict]:
        """Parse fly.toml configuration"""
        try:
            content = file_path.read_text(encoding="utf-8")
            config = toml.loads(content)
            return {
                "app": config.get("app", "unknown"),
                "primary_region": config.get("primary_region", "unknown"),
                "env": config.get("env", {}),
                "http_service": config.get("http_service", {}),
                "vm": config.get("vm", [{}])[0]
                if isinstance(config.get("vm"), list)
                else config.get("vm", {}),
            }
        except Exception as e:
            print(f"{Colors.WARNING}âš  Error parsing {file_path}: {e}{Colors.ENDC}")
            return None

    def parse_docker_compose(self, file_path: Path) -> Optional[Dict]:
        """Parse docker-compose.yml"""
        try:
            content = file_path.read_text(encoding="utf-8")
            config = yaml.safe_load(content)
            services = config.get("services", {})
            return {
                "services": list(services.keys()),
                "service_details": {
                    name: {
                        "image": svc.get("image", "custom"),
                        "ports": svc.get("ports", []),
                    }
                    for name, svc in services.items()
                },
            }
        except Exception as e:
            print(f"{Colors.WARNING}âš  Error parsing {file_path}: {e}{Colors.ENDC}")
            return None

    def parse_prometheus_config(self, file_path: Path) -> Optional[Dict]:
        """Parse prometheus.yml"""
        try:
            content = file_path.read_text(encoding="utf-8")
            config = yaml.safe_load(content)
            scrape_configs = config.get("scrape_configs", [])
            return {
                "global": config.get("global", {}),
                "scrape_jobs": [sc.get("job_name") for sc in scrape_configs],
                "scrape_configs": scrape_configs,
            }
        except Exception as e:
            print(f"{Colors.WARNING}âš  Error parsing {file_path}: {e}{Colors.ENDC}")
            return None

    def generate(self) -> bool:
        """Generate INFRASTRUCTURE_STATUS.md"""
        # Collect all infrastructure info
        fly_configs = {}
        docker_configs = {}
        prometheus_config = None

        # Find fly.toml files
        for f in self.root_dir.rglob("fly.toml"):
            if "__pycache__" not in str(f) and "node_modules" not in str(f):
                info = self.parse_fly_toml(f)
                if info:
                    fly_configs[str(f.relative_to(self.root_dir))] = info

        # Find docker-compose files
        for f in self.root_dir.glob("docker-compose*.yml"):
            info = self.parse_docker_compose(f)
            if info:
                docker_configs[f.name] = info

        # Find prometheus config
        prom_file = self.config_dir / "prometheus" / "prometheus.yml"
        if prom_file.exists():
            prometheus_config = self.parse_prometheus_config(prom_file)

        # Generate markdown
        lines = [
            "# INFRASTRUCTURE STATUS",
            "",
            f"*Auto-generated by The Scribe on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            "> **Note:** This document is automatically updated. Do not edit manually.",
            "",
            "---",
            "",
            "## Summary",
            "",
            f"- **Fly.io Apps:** {len(fly_configs)}",
            f"- **Docker Compose Files:** {len(docker_configs)}",
            f"- **Prometheus Jobs:** {len(prometheus_config['scrape_jobs']) if prometheus_config else 0}",
            "",
            "---",
            "",
        ]

        # Fly.io Section
        if fly_configs:
            lines.extend(
                [
                    "## Fly.io Deployments",
                    "",
                    "| App | Region | Path |",
                    "|-----|--------|------|",
                ]
            )
            for path, config in fly_configs.items():
                lines.append(
                    f"| `{config['app']}` | {config['primary_region']} | `{path}` |"
                )

            lines.extend(["", "### Deployment Details", ""])

            for path, config in fly_configs.items():
                lines.extend(
                    [
                        f"#### {config['app']}",
                        "",
                        f"- **Region:** {config['primary_region']}",
                        f"- **Config:** `{path}`",
                    ]
                )
                if config.get("vm"):
                    vm = config["vm"]
                    if vm.get("size"):
                        lines.append(f"- **VM Size:** {vm.get('size')}")
                    if vm.get("memory"):
                        lines.append(f"- **Memory:** {vm.get('memory')}")

                if config.get("http_service"):
                    http = config["http_service"]
                    lines.append(
                        f"- **Internal Port:** {http.get('internal_port', 'N/A')}"
                    )
                    lines.append(f"- **Concurrency:** {http.get('concurrency', {})}")

                lines.extend(["", "---", ""])

        # Docker Section
        if docker_configs:
            lines.extend(
                [
                    "## Docker Compose Services",
                    "",
                ]
            )

            for compose_file, config in docker_configs.items():
                lines.extend(
                    [
                        f"### {compose_file}",
                        "",
                        "| Service | Image | Ports |",
                        "|---------|-------|-------|",
                    ]
                )
                for name, details in config["service_details"].items():
                    ports = ", ".join(details["ports"]) if details["ports"] else "N/A"
                    lines.append(f"| `{name}` | `{details['image']}` | {ports} |")
                lines.extend(["", "---", ""])

        # Prometheus Section
        if prometheus_config:
            lines.extend(
                [
                    "## Prometheus Monitoring",
                    "",
                    f"**Scrape Interval:** {prometheus_config['global'].get('scrape_interval', 'N/A')}",
                    "",
                    "### Scrape Jobs",
                    "",
                    "| Job Name | Targets |",
                    "|----------|---------|",
                ]
            )
            for sc in prometheus_config["scrape_configs"]:
                targets = sc.get("static_configs", [{}])[0].get("targets", [])
                targets_str = ", ".join(targets[:3])
                if len(targets) > 3:
                    targets_str += f" (+{len(targets) - 3} more)"
                lines.append(f"| `{sc['job_name']}` | {targets_str} |")

            lines.extend(["", "---", ""])

        lines.append(f"*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        self.output_file.write_text("\n".join(lines), encoding="utf-8")
        print(f"{Colors.OKGREEN}âœ” Generated {self.output_file}{Colors.ENDC}")
        return True


class ArchitectureStatsGenerator:
    """Update statistics in ARCHITECTURE.md"""

    def __init__(self, backend_dir: Path, frontend_dir: Path, docs_dir: Path):
        self.backend_dir = backend_dir
        self.frontend_dir = frontend_dir
        self.output_file = docs_dir / "ARCHITECTURE_STATS.md"

    def count_files(self, directory: Path, pattern: str) -> int:
        """Count files matching pattern"""
        if not directory.exists():
            return 0
        files = list(directory.rglob(pattern))
        return len(
            [
                f
                for f in files
                if "__pycache__" not in str(f) and "node_modules" not in str(f)
            ]
        )

    def count_lines(self, directory: Path, pattern: str) -> int:
        """Count total lines in files matching pattern"""
        if not directory.exists():
            return 0
        total = 0
        for f in directory.rglob(pattern):
            if "__pycache__" not in str(f) and "node_modules" not in str(f):
                try:
                    total += len(f.read_text(encoding="utf-8").split("\n"))
                except Exception:
                    pass
        return total

    def generate(self) -> bool:
        """Generate ARCHITECTURE_STATS.md"""
        # Collect stats
        stats = {
            "backend_py_files": self.count_files(self.backend_dir, "*.py"),
            "backend_py_lines": self.count_lines(self.backend_dir, "*.py"),
            "frontend_ts_files": self.count_files(self.frontend_dir / "src", "*.ts")
            + self.count_files(self.frontend_dir / "src", "*.tsx"),
            "frontend_ts_lines": self.count_lines(self.frontend_dir / "src", "*.ts")
            + self.count_lines(self.frontend_dir / "src", "*.tsx"),
            "routers": self.count_files(self.backend_dir / "app" / "routers", "*.py"),
            "services": self.count_files(self.backend_dir / "services", "*.py"),
            "migrations": self.count_files(
                self.backend_dir / "migrations", "migration_*.py"
            ),
            "tests": self.count_files(self.backend_dir.parent / "tests", "test_*.py"),
            "components": self.count_files(
                self.frontend_dir / "src" / "components", "*.tsx"
            ),
        }

        # Generate markdown
        lines = [
            "# ARCHITECTURE STATISTICS",
            "",
            f"*Auto-generated by The Scribe on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            "> **Note:** This document is automatically updated. Do not edit manually.",
            "",
            "---",
            "",
            "## Codebase Statistics",
            "",
            "### Backend (Python)",
            "",
            "| Metric | Count |",
            "|--------|-------|",
            f"| Python Files | {stats['backend_py_files']} |",
            f"| Lines of Code | ~{stats['backend_py_lines']:,} |",
            f"| API Routers | {stats['routers']} |",
            f"| Services | {stats['services']} |",
            f"| Migrations | {stats['migrations']} |",
            f"| Test Files | {stats['tests']} |",
            "",
            "### Frontend (TypeScript/React)",
            "",
            "| Metric | Count |",
            "|--------|-------|",
            f"| TypeScript Files | {stats['frontend_ts_files']} |",
            f"| Lines of Code | ~{stats['frontend_ts_lines']:,} |",
            f"| React Components | {stats['components']} |",
            "",
            "---",
            "",
            "## Quick Reference",
            "",
            "```",
            f"Backend:  {stats['backend_py_files']} files, ~{stats['backend_py_lines'] // 1000}k LOC",
            f"Frontend: {stats['frontend_ts_files']} files, ~{stats['frontend_ts_lines'] // 1000}k LOC",
            f"Total:    {stats['backend_py_files'] + stats['frontend_ts_files']} files",
            "```",
            "",
            "---",
            "",
            f"*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
        ]

        self.output_file.write_text("\n".join(lines), encoding="utf-8")
        print(f"{Colors.OKGREEN}âœ” Generated {self.output_file}{Colors.ENDC}")
        return True


class ScribeExtended:
    """Extended Scribe - runs all documentation generators"""

    def __init__(self, root_dir: Path):
        self.root_dir = root_dir
        self.backend_dir = root_dir / "apps" / "backend-rag" / "backend"
        self.frontend_dir = root_dir / "apps" / "mouth"
        self.docs_dir = root_dir / "docs"

    def run(self) -> bool:
        """Run all extended generators"""
        print(f"{Colors.HEADER}{Colors.BOLD}")
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘   THE SCRIBE EXTENDED: AUTO-DOCS       â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"{Colors.ENDC}")

        self.docs_dir.mkdir(parents=True, exist_ok=True)

        success = True

        # Run all generators
        generators = [
            (
                "Migrations Changelog",
                MigrationsGenerator(self.backend_dir, self.docs_dir),
            ),
            (
                "Plugin Registry",
                PluginRegistryGenerator(self.backend_dir, self.docs_dir),
            ),
            (
                "Infrastructure Status",
                InfrastructureGenerator(self.root_dir, self.docs_dir),
            ),
            (
                "Architecture Stats",
                ArchitectureStatsGenerator(
                    self.backend_dir, self.frontend_dir, self.docs_dir
                ),
            ),
        ]

        for name, generator in generators:
            print(f"\n{Colors.OKCYAN}ğŸ“š Generating {name}...{Colors.ENDC}")
            try:
                if not generator.generate():
                    success = False
            except Exception as e:
                print(f"{Colors.FAIL}âœ˜ Error generating {name}: {e}{Colors.ENDC}")
                success = False

        return success


def main():
    """Main entry point"""
    import sys

    script_dir = Path(__file__).parent
    root_dir = script_dir.parent.parent

    scribe = ScribeExtended(root_dir)
    success = scribe.run()

    if success:
        print(
            f"\n{Colors.OKGREEN}{Colors.BOLD}âœ” All extended documentation generated!{Colors.ENDC}"
        )
    else:
        print(f"\n{Colors.WARNING}âš  Some generators had issues{Colors.ENDC}")

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
